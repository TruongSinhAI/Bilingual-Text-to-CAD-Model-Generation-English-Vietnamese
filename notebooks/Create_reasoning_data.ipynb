{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "063e5657-56a7-4fa4-bf29-561359c51de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import google as genai\n",
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "411366aa-4d6f-4373-9251-554524e78f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset, DatasetDict \n",
    "import math\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "from huggingface_hub import create_repo, upload_folder\n",
    "import json \n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from pathlib import Path\n",
    "import concurrent.futures\n",
    "from json_repair import repair_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e778c9b-6c1a-4021-a259-43412dde3cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_json_files(folder_path):\n",
    "    \"\"\"\n",
    "    Đọc tất cả các file JSON trong một thư mục và lưu chúng vào một mảng.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Đường dẫn đến thư mục chứa các file JSON.\n",
    "\n",
    "    Returns:\n",
    "        list: Một danh sách chứa nội dung của tất cả các file JSON đã đọc.\n",
    "              Trả về một danh sách rỗng nếu thư mục không tồn tại hoặc không có file JSON nào.\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(f\"Lỗi: Thư mục '{folder_path}' không tồn tại.\")\n",
    "        return all_data\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(\".json\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    data = json.load(f)\n",
    "                    all_data.append(data)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Lỗi: Không thể giải mã JSON từ file '{file_path}'.\")\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Lỗi: Không tìm thấy file '{file_path}'.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Lỗi khi đọc file '{file_path}': {e}\")\n",
    "    return all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2abd10cc-3410-42a6-921d-76e763615eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = process_json_files('results_not_done4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "417b4b13-a1b4-4e96-a002-4411b6faa06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gemini:\n",
    "    def __init__(self, api_key):\n",
    "        self.client = genai.Client(api_key = api_key)\n",
    "        self.model_name =\"gemini-2.5-flash\"\n",
    "        self.config()\n",
    "\n",
    "    def config(self):\n",
    "        self.generate_content_config = types.GenerateContentConfig(\n",
    "            response_mime_type=\"application/json\",\n",
    "            response_schema=genai.types.Schema(\n",
    "                type = genai.types.Type.OBJECT,\n",
    "                required = [\"result\"],\n",
    "                properties = {\n",
    "                    \"result\": genai.types.Schema(\n",
    "                        type = genai.types.Type.ARRAY,\n",
    "                        items = genai.types.Schema(\n",
    "                            type = genai.types.Type.STRING,\n",
    "                        ),\n",
    "                    ),\n",
    "                },\n",
    "            ),\n",
    "            system_instruction=[\n",
    "                types.Part.from_text(text = \"\"\"\n",
    "I have a CAD JSON file (used to create CAD) and a description of the JSON, YOU WILL RECIVE MANY JSON-COMPLETTION, Please return into json format for each pairs, each pair separate by \"\\n======================================\".\n",
    "\n",
    "YOU NEED TO RESPONSE ME BY JSON FORMAT ARRAY.\n",
    "IN THE VALUE YOU RESPONSE PLEASE USING `\\\"` INSTEAD `\"`\n",
    "RESPONSE IN VIETNAMESE\n",
    "FOLLOWING THESE STEPS:\n",
    "\n",
    "*S1: Remove the excess description immediately after the extrusion description.\n",
    "\n",
    "**Example:\n",
    "<description>\n",
    "Part 1: Three-dimensional rectangular prism with a flat top and bottom. Create a new coordinate system with the following properties: * Euler Angles: (0.0, 0.0, -90.0) * Translation Vector: (0.0, 0.0316, 0.0). Draw a 2D sketch on the XY plane of the coordinate system. Create a face containing one closed loop made up of 4 lines: * Line 1: Start Point (0.0, 0.0), End Point (0.75, 0.0) * Line 2: Start Point (0.75, 0.0), End Point (0.75, 0.6772) * Line 3: Start Point (0.75, 0.6772), End Point (0.0, 0.6772) * Line 4: Start Point (0.0, 0.6772), End Point (0.0, 0.0). Scale the 2D sketch by a factor of 0.75. Transform the scaled 2D sketch into a 3D sketch using the defined coordinate system. Extrude the 3D sketch by 0.0316 units in the positive Z direction. The height of this part is 0.75 units, the width is 0.0316 units, and the length is 0.75 units. This completes the three-dimensional rectangular prism part.\n",
    "</description>\n",
    "\n",
    "-> You need to remove the line: \"The height of this part is 0.75 units, the width is 0.0316 units, and the length is 0.75 units. This completes the three-dimensional rectangular prism part.\" Keep the </description> tag.\n",
    "The output you need to return after removing the excess description would look like:\n",
    "\n",
    "<description>\n",
    "Part 1: Three-dimensional rectangular prism with a flat top and bottom. Create a new coordinate system with the following properties: * Euler Angles: (0.0, 0.0, -90.0) * Translation Vector: (0.0, 0.0316, 0.0). Draw a 2D sketch on the XY plane of the coordinate system. Create a face containing one closed loop made up of 4 lines: * Line 1: Start Point (0.0, 0.0), End Point (0.75, 0.0) * Line 2: Start Point (0.75, 0.0), End Point (0.75, 0.6772) * Line 3: Start Point (0.75, 0.6772), End Point (0.0, 0.6772) * Line 4: Start Point (0.0, 0.6772), End Point (0.0, 0.0). Scale the 2D sketch by a factor of 0.75. Transform the scaled 2D sketch into a 3D sketch using the defined coordinate system. Extrude the 3D sketch by 0.0316 units in the positive Z direction.\n",
    "</description>\n",
    "**\n",
    "\n",
    "*S2: Check if the newly created description matches the json. If it does, create \"<valid>Yes</valid>\", if it doesn't, create \"<valid>No</valid>\"\n",
    "\n",
    "*S3: Create a sample reasoning data enclosed in <think> ... </think>. The reasoning data should follow two steps:\n",
    "Step 1: Reason out the components that will be in the JSON based on the given description.\n",
    "Step 2: Check the logic, arithmetic correctness, and make corrections (if necessary) from Step 1.\n",
    "\n",
    "**Example 1 sample:\n",
    "\n",
    "***Input:\n",
    "<json> {{\"parts\": {{\"part_1\": {{\"coordinate_system\": {{\"Euler Angles\": [0.0, 0.0, -90.0], \"Translation Vector\": [0.0, 0.0316, 0.0]}}, \"sketch\": {{\"face_1\": {{\"loop_1\": {{\"line_1\": {{\"Start Point\": [0.0, 0.0], \"End Point\": [0.75, 0.0]}}, \"line_2\": {{\"Start Point\": [0.75, 0.0], \"End Point\": [0.75, 0.6772]}}, \"line_3\": {{\"Start Point\": [0.75, 0.6772], \"End Point\": [0.0, 0.6772]}}, \"line_4\": {{\"Start Point\": [0.0, 0.6772], \"End Point\": [0.0, 0.0]}}}}}}, \"extrusion\": {{\"extrude_depth_towards_normal\": 0.0316, \"extrude_depth_opposite_normal\": 0.0, \"sketch_scale\": 0.75, \"operation\": \"NewBodyFeatureOperation\"}}}}}}}} </json>\n",
    "<description> Part 1: Three-dimensional rectangular prism with a flat top and bottom. Create a new coordinate system with the following properties: * Euler Angles: (0.0, 0.0, -90.0) * Translation Vector: (0.0, 0.0316, 0.0). Draw a 2D sketch on the XY plane of the coordinate system. Create a face containing one closed loop made up of 4 lines: * Line 1: Start Point (0.0, 0.0), End Point (0.75, 0.0) * Line 2: Start Point (0.75, 0.0), End Point (0.75, 0.6772) * Line 3: Start Point (0.75, 0.6772), End Point (0.0, 0.6772) * Line 4: Start Point (0.0, 0.6772), End Point (0.0, 0.0). Scale the 2D sketch by a factor of 0.75. Transform the scaled 2D sketch into a 3D sketch using the defined coordinate system. Extrude the 3D sketch by 0.0316 units in the positive Z direction. </description>\n",
    "\n",
    "***Output:\n",
    "S1:\n",
    "<description>\n",
    "Part 1: Three-dimensional rectangular prism with a flat top and bottom. Create a new coordinate system with the following properties: * Euler Angles: (0.0, 0.0, -90.0) * Translation Vector: (0.0, 0.0316, 0.0). Draw a 2D sketch on the XY plane of the coordinate system. Create a face containing one closed loop made up of 4 lines: * Line 1: Start Point (0.0, 0.0), End Point (0.75, 0.0) * Line 2: Start Point (0.75, 0.0), End Point (0.75, 0.6772) * Line 3: Start Point (0.75, 0.6772), End Point (0.0, 0.6772) * Line 4: Start Point (0.0, 0.6772), End Point (0.0, 0.0). Scale the 2D sketch by a factor of 0.75. Transform the scaled 2D sketch into a 3D sketch using the defined coordinate system. Extrude the 3D sketch by 0.0316 units in the positive Z direction.\n",
    "</description>\n",
    "S2:\n",
    "<valid>Yes</valid>\n",
    "S3:\n",
    "<think>\n",
    "***Step 1: Infer the components that will be in the json based on the provided description:\n",
    "\n",
    "parts:From the description, we have a single part labeled \"part_1\" describing a three-dimensional rectangular prism. This will be reflected in the json as \"part_1\".\n",
    "\n",
    "part_1: (Rectangular Prism)\n",
    "-coordinate_system:\n",
    "--Euler Angles: [0.0, 0.0, -90.0] (Derived from the description: \"Create a new coordinate system with the following properties: * Euler Angles: (0.0, 0.0, -90.0)\").\n",
    "--Translation Vector: [0.0, 0.0316, 0.0] (Derived from the description: \"Translation Vector: (0.0, 0.0316, 0.0)\").\n",
    "-sketch:\n",
    "--face_1:\n",
    "---loop_1:\n",
    "----line_1: Start [0.0, 0.0], End [0.75, 0.0] (Derived from the description: \"Line 1: Start Point (0.0, 0.0), End Point (0.75, 0.0)\").\n",
    "----line_2: Start [0.75, 0.0], End [0.75, 0.6772] (Derived from the description: \"Line 2: Start Point (0.75, 0.0), End Point (0.75, 0.6772)\").\n",
    "----line_3: Start [0.75, 0.6772], End [0.0, 0.6772] (Derived from the description: \"Line 3: Start Point (0.75, 0.6772), End Point (0.0, 0.6772)\").\n",
    "----line_4: Start [0.0, 0.6772], End [0.0, 0.0] (Derived from the description: \"Line 4: Start Point (0.0, 0.6772), End Point (0.0, 0.0)\").\n",
    "-extrusion:\n",
    "--extrude_depth_towards_normal: 0.0316 (Derived from the description: \"Extrude the 3D sketch by 0.0316 units in the positive Z direction\").\n",
    "--extrude_depth_opposite_normal: 0.0 (Not mentioned in the description, but inferred as 0 because no extrusion is required in the opposite direction).\n",
    "--sketch_scale: 0.75 (Derived from the description: \"Scale the 2D sketch by a factor of 0.75\").\n",
    "--operation: \"NewBodyFeatureOperation\" (Inferred from the description: \"Create a 3D model of the rectangular prism\").\n",
    "\n",
    "***Step 2: Check the logic, arithmetic correctness, and make corrections (if necessary) from Step 1:\n",
    "\n",
    "-Check the lines (line_1, line_2, line_3, line_4):\n",
    "line_1 (Start [0.0, 0.0], End [0.75, 0.0]) connects correctly with line_2 (Start [0.75, 0.0], End [0.75, 0.6772]).\n",
    "line_2 (Start [0.75, 0.0], End [0.75, 0.6772]) connects correctly with line_3 (Start [0.75, 0.6772], End [0.0, 0.6772]).\n",
    "line_3 (Start [0.75, 0.6772], End [0.0, 0.6772]) connects correctly with line_4 (Start [0.0, 0.6772], End [0.0, 0.0]).\n",
    "line_4 (Start [0.0, 0.6772], End [0.0, 0.0]) connects correctly with line_1 (Start [0.0, 0.0], End [0.75, 0.0]).\n",
    "\n",
    "--Result: The sketch loop is valid and closed.\n",
    "\n",
    "-Check the extrusion:\n",
    "Extrusion of the 3D sketch with a depth of 0.0316 units in the positive Z direction, as specified in the description.\n",
    "No extrusion is needed in the opposite direction, so extrude_depth_opposite_normal is correctly set to 0.\n",
    "\n",
    "--Result: The extrusion is correct and matches the requirements.\n",
    "\n",
    "-Check dimensions consistency:\n",
    "The values for the Start/End points of the lines are correctly represented and match the 2D sketch described.\n",
    "The extrusion depth and scale factor are consistent with the description.\n",
    "\n",
    "--Result: The dimensions are correct and consistent.\n",
    "\n",
    "-Correction: This inferred data is accurate and does not require further modifications.\n",
    "</think>\n",
    "**\n",
    "\"\"\"),\n",
    "            ],\n",
    "            # thinking_config=types.ThinkingConfig(thinking_budget=0)\n",
    "        )\n",
    "\n",
    "    # def fix_json(self, text):\n",
    "    #     def replace_quote(match):\n",
    "    #         quote = match.group(0)\n",
    "    #         start_pos = match.start()\n",
    "    #         end_pos = match.end()\n",
    "            \n",
    "    #         # Kiểm tra ký tự trước và sau\n",
    "    #         char_before = text[start_pos - 1] if start_pos > 0 else ''\n",
    "    #         char_after = text[end_pos] if end_pos < len(text) else ''\n",
    "            \n",
    "    #         # Ngoại trừ: có > trước hoặc < sau\n",
    "    #         if char_before == '>' or char_after == '<':\n",
    "    #             return quote\n",
    "            \n",
    "    #         # Kiểm tra trường hợp \"result\"\n",
    "    #         # Lấy context xung quanh để kiểm tra\n",
    "    #         context_start = max(0, start_pos - 7)\n",
    "    #         context_end = min(len(text), end_pos + 7)\n",
    "    #         context = text[context_start:context_end]\n",
    "            \n",
    "    #         if '\"result\"' in context:\n",
    "    #             # Kiểm tra chính xác vị trí\n",
    "    #             result_pattern = r'\"result\"'\n",
    "    #             for result_match in re.finditer(result_pattern, context):\n",
    "    #                 result_start = context_start + result_match.start()\n",
    "    #                 result_end = context_start + result_match.end()\n",
    "    #                 if result_start <= start_pos < result_end:\n",
    "    #                     return quote\n",
    "            \n",
    "    #         # Kiểm tra xem đã có dấu \\ trước chưa\n",
    "    #         if char_before == '\\\\':\n",
    "    #             return quote\n",
    "            \n",
    "    #         return '\\\\' + quote\n",
    "    \n",
    "    #     # Tìm tất cả dấu \" và thay thế\n",
    "    #     result = re.sub(r'\"', replace_quote, text)\n",
    "    #     return repair_json(result)\n",
    "\n",
    "    def extract(self, text):\n",
    "        \"\"\"\n",
    "        Tìm và trích xuất tất cả các đoạn text bắt đầu bằng <description> và kết thúc bằng </think>\n",
    "        \n",
    "        Args:\n",
    "            text (str): Văn bản đầu vào\n",
    "            \n",
    "        Returns:\n",
    "            list: Danh sách các đoạn text được tìm thấy\n",
    "        \"\"\"\n",
    "        # Pattern để tìm các đoạn từ <description> đến </think>\n",
    "        pattern = r'<description>.*?</think>'\n",
    "        \n",
    "        # Tìm tất cả các đoạn khớp với pattern (DOTALL để . khớp với \\n)\n",
    "        matches = re.findall(pattern, text, re.DOTALL)\n",
    "        \n",
    "        return matches\n",
    "\n",
    "    \n",
    "    def ask_gemini(self, inputs:str) -> list[str]:\n",
    "\n",
    "        try:\n",
    "            response = self.client.models.generate_content(\n",
    "                model=self.model_name,\n",
    "                contents=inputs,\n",
    "                config=self.generate_content_config,\n",
    "            )\n",
    "            ans = self.extract(response.text)\n",
    "            if len(ans) == 5:\n",
    "                return ans\n",
    "\n",
    "        except:\n",
    "            response = self.client.models.generate_content(\n",
    "                    model= \"gemini-2.5-flash-lite-preview-06-17\",\n",
    "                    contents=inputs,\n",
    "                    config=self.generate_content_config,\n",
    "                )\n",
    "            ans = self.extract(response.text)\n",
    "            if len(ans) == 5:\n",
    "                return ans\n",
    "        return [''] * 5\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5b6f743-477f-4ed0-b864-a415bc4e4ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "api_keys_string = os.getenv(\"API_KEY_LIST\")\n",
    "api_keys = api_keys_string.split(\",\") if api_keys_string else []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddc62881-7e66-47c4-8321-bd3e6ba1854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_split = \"range_500_1000_vi\"\n",
    "start = 0#500  * 5* len(api_keys)*2\n",
    "end = 500  * 5* len(api_keys)  # max_request * batch_size * num_of_accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f9dcdbc-b40c-49b1-bba0-aa0b2a4730fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 25000 samples from index 0 to 25000\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"wanhin/cad_hqh1\", split=old_split)\n",
    "    \n",
    "# Filter dataset based on start and end indices\n",
    "filtered_dataset = dataset.select(range(start, min(end, len(dataset))))\n",
    "print(f\"Processing {len(filtered_dataset)} samples from index {start} to {min(end, len(dataset))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b864ca47-e028-4b79-a17e-75ece8e3b200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_workers = len(api_keys)\n",
    "gemini_clients = [Gemini(api_key) for api_key in api_keys]\n",
    "n_workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d13cbf77-8bc0-4f7b-bf40-121efe68d059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(gemini: Gemini, data_chunk: list[dict], worker_id: int, batch_size: int = 5):\n",
    "    results = []\n",
    "    for i in range(0, len(data_chunk), batch_size):\n",
    "        batch = data_chunk[i:i + batch_size]\n",
    "        inputs = \"\"\n",
    "        for idx in range(5): #batchsize\n",
    "            inputs += batch['completion'][idx] + '\\n\\n' + batch['prompt'][idx] +\"\\n======================================\"\n",
    "            \n",
    "        try:\n",
    "            response = gemini.ask_gemini(inputs)\n",
    "            batch['reasoning'] = response\n",
    "            batch_dicts = [dict(zip(batch, values)) for values in zip(*batch.values())]\n",
    "            results += batch_dicts\n",
    "        except Exception as e:\n",
    "            # print(f\"Worker {worker_id} - Error in batch {i}: {e}\")\n",
    "            continue\n",
    "        save_result(batch_dicts, index=f\"{worker_id}_{i}\", save_dir=\"vi_1\", filename_prefix=\"part\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddd3359c-720b-483f-a531-a36373f59372",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from datasets import concatenate_datasets\n",
    "\n",
    "def chunk_data(dataset: Dataset, n_chunks: int) -> list[Dataset]:\n",
    "    length = len(dataset)\n",
    "    chunk_size = length // n_chunks\n",
    "    chunks = [Dataset.from_dict(dataset[i * chunk_size : (i + 1) * chunk_size]) for i in range(n_chunks)]\n",
    "\n",
    "    # Xử lý phần dư nếu có\n",
    "    remainder_start = n_chunks * chunk_size\n",
    "    if remainder_start < length:\n",
    "        remainder = dataset.select(range(remainder_start, length))  # đây là Dataset\n",
    "        chunks[-1] = concatenate_datasets([chunks[-1], remainder])\n",
    "\n",
    "    return chunks\n",
    "\n",
    "data_chunks = chunk_data(filtered_dataset, n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88f57fba-cb13-4adc-abb9-e8cc7af2649d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Dataset({\n",
       "     features: ['prompt', 'completion'],\n",
       "     num_rows: 2500\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'completion'],\n",
       "     num_rows: 2500\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'completion'],\n",
       "     num_rows: 2500\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'completion'],\n",
       "     num_rows: 2500\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'completion'],\n",
       "     num_rows: 2500\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'completion'],\n",
       "     num_rows: 2500\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'completion'],\n",
       "     num_rows: 2500\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'completion'],\n",
       "     num_rows: 2500\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'completion'],\n",
       "     num_rows: 2500\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'completion'],\n",
       "     num_rows: 2500\n",
       " })]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9361e754-e032-4c4b-9539-083cd1eb6303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result(results: list[dict], index: int, save_dir=\"results\", filename_prefix=\"reasoning\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    save_path = os.path.join(save_dir, f\"{filename_prefix}_{index}.json\")\n",
    "\n",
    "    with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    # print(f\"Saved {len(results)} items to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf126266-666c-4818-9ae7-4a0ad5dd468d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [6:54:01, 2484.16s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "all_results = []\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=n_workers) as executor:\n",
    "    futures = [\n",
    "        executor.submit(process_data, gemini_clients[i], data_chunks[i], i, batch_size=5)\n",
    "        for i in range(n_workers)\n",
    "    ]\n",
    "    for future in tqdm(concurrent.futures.as_completed(futures)):\n",
    "        all_results.extend(future.result())\n",
    "save_result(all_results, 0, 'results_vi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0700eeb-da67-47e5-bfa6-9c563dafc458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46c7d57f-2740-4941-ad50-076b7e98ba54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9095"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c0bd6b-2f26-4b18-997d-77b34772754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_result(all_results, 0000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d3189e6-387b-4f71-a980-33c38d28df9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hehe = []\n",
    "for sample in now:\n",
    "    hehe.extend(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4e29b74-f04b-4ef5-99d8-0e2996c35156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5995"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hehe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e98cab1d-7461-4ae1-95c1-d6f59d07585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for sample in all_results:\n",
    "    if sample['reasoning'] != '':\n",
    "        c+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16a08e04-5406-4e60-bb1b-999542b6dd7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5305"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cfd9bf1-989c-44f1-b0f6-cb8eb4443a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tags(text, tag_name):\n",
    "    \"\"\"Extract content from XML-like tags\"\"\"\n",
    "    pattern = f\"<{tag_name}>(.*?)</{tag_name}>\"\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    return matches[0] if matches else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6866e051-bb05-4c3c-b2f0-ffd5e9bb0b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = []\n",
    "invalid_indices = []\n",
    "c2 = 0\n",
    "c3 = 0\n",
    "c4 = 0\n",
    "for sample in all_results:\n",
    "    if sample['reasoning'] != '':\n",
    "        c4 += 1\n",
    "        response_text = sample['reasoning']\n",
    "        valid_tag = extract_tags(response_text, \"valid\")\n",
    "        if valid_tag and valid_tag.strip() == \"Yes\":\n",
    "            # Extract description and reasoning\n",
    "            description_tag = extract_tags(response_text, \"description\")\n",
    "            think_tag = extract_tags(response_text, \"think\")\n",
    "            \n",
    "            if description_tag and think_tag:\n",
    "                # Create new sample\n",
    "                new_sample = {\n",
    "                    \"description\": f\"<description>{description_tag}</description>\",\n",
    "                    \"reasoning\": f\"<think>{think_tag}</think>\",\n",
    "                    \"completion\": sample['completion']\n",
    "                }\n",
    "                new_data.append(new_sample)\n",
    "            else:\n",
    "                c3 += 1\n",
    "        else:\n",
    "            c2 += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71d9c25e-f6bf-4250-8fb1-77387766c8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1293"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68995bf7-f743-4e28-a233-413b57fe9f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3997"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76d93544-b476-4baf-b103-541910bdc4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "    \n",
    "new_dataset = Dataset.from_list(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7c8505-cd38-4b21-be84-4f58127994a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b43d1edc03c349e2831f32a8e19aebde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b922e98b021c43fd819929a268294618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c44c917e4d084574a28bf1d604065690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/875 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/TruongSinhAI/cad_reasoning/commit/500c48474aea836d3a5929a195719399a20bdd38', commit_message='Upload dataset', commit_description='', oid='500c48474aea836d3a5929a195719399a20bdd38', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/TruongSinhAI/cad_reasoning', endpoint='https://huggingface.co', repo_type='dataset', repo_id='TruongSinhAI/cad_reasoning'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "repo_id = \"TruongSinhAI/cad_reasoning\"\n",
    "token = \"tokennn\"  \n",
    "new_dataset.push_to_hub(repo_id, private=False, token=token, split=\"range_500_1000_vi_0_50000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "414c7087-2a1d-40a5-8cba-eac35c83f77e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cf4e2a1c50247d5b3b05d64616099fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/764 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab02e88c70c44ad81db5b502efb400a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)0_1000_en_0_25000-00000-of-00001.parquet:   0%|          | 0.00/9.88M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c547b87861f84e31a679a6e9faf52529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)00_en_25000_50000-00000-of-00001.parquet:   0%|          | 0.00/2.61M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "116b22968c6d4472b8fc8cbf2bc60db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)1000_en_50000_end-00000-of-00001.parquet:   0%|          | 0.00/4.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c21fab817f8849fcbc75009366f577df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating range_500_1000_en_0_25000 split:   0%|          | 0/6152 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4f66eac9bb04568b486a3f981872fc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating range_500_1000_en_25000_50000 split:   0%|          | 0/1632 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b472f28061534375ba6464a967655cfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating range_500_1000_en_50000_end split:   0%|          | 0/3007 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = load_dataset(\"TruongSinhAI/cad_reasoning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "266be371-f611-4942-8ad0-0405123b2f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import concatenate_datasets\n",
    "\n",
    "merged_dataset = concatenate_datasets([\n",
    "    data['range_500_1000_en_0_25000'],\n",
    "    data['range_500_1000_en_25000_50000'],\n",
    "    data['range_500_1000_en_50000_end']\n",
    "])\n",
    "\n",
    "# Chuyển sang pandas DataFrame\n",
    "df = merged_dataset.to_pandas()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77200886-1806-4614-9c85-352e2fb0a7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"merged_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "405f6e04-8112-4328-b94c-fbacc70088f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>completion</th>\n",
       "      <th>description_trans</th>\n",
       "      <th>reasoning_trans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;description&gt;&lt;part\\\\_1&gt; - Construct a rectangu...</td>\n",
       "      <td>&lt;think&gt;\\n***Step 1: Infer the components that ...</td>\n",
       "      <td>&lt;json&gt;\\n{\"parts\":{\"part_1\":{\"coordinate_system...</td>\n",
       "      <td>&lt;description&gt;&lt;part\\\\_1&gt; - Dựng một lăng trụ đứ...</td>\n",
       "      <td>&lt;think&gt;\\n***Bước 1: Suy ra các thành phần sẽ c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;description&gt;Part 1: Cylindrical Object with T...</td>\n",
       "      <td>&lt;think&gt;\\n***Step 1: Infer the components that ...</td>\n",
       "      <td>&lt;json&gt;\\n{\"parts\":{\"part_1\":{\"coordinate_system...</td>\n",
       "      <td>&lt;description&gt;Phần 1: Đối tượng hình trụ có đầu...</td>\n",
       "      <td>&lt;think&gt;\\n***Bước 1: Suy ra các thành phần sẽ c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;description&gt;**Part 1: A rectangular prism wit...</td>\n",
       "      <td>&lt;think&gt;\\n***Step 1: Infer the components that ...</td>\n",
       "      <td>&lt;json&gt;\\n{\"parts\":{\"part_1\":{\"coordinate_system...</td>\n",
       "      <td>&lt;description&gt;**Phần 1: Lăng trụ chữ nhật có cạ...</td>\n",
       "      <td>&lt;think&gt;\\n***Bước 1: Suy ra các thành phần sẽ c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;description&gt;Part 1: Rectangular Table Top The...</td>\n",
       "      <td>&lt;think&gt;\\n***Step 1: Infer the components that ...</td>\n",
       "      <td>&lt;json&gt;\\n{\"parts\":{\"part_1\":{\"coordinate_system...</td>\n",
       "      <td>&lt;description&gt;Phần 1: Mặt bàn hình chữ nhật Phầ...</td>\n",
       "      <td>&lt;think&gt;\\n***Bước 1: Suy ra các thành phần sẽ c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;description&gt; **Part 1: Building a rectangular...</td>\n",
       "      <td>&lt;think&gt;\\n***Step 1: Infer the components that ...</td>\n",
       "      <td>&lt;json&gt;\\n{\"parts\":{\"part_1\":{\"coordinate_system...</td>\n",
       "      <td>&lt;description&gt; **Phần 1: Xây dựng một lăng trụ ...</td>\n",
       "      <td>&lt;think&gt;\\n***Bước 1: Suy ra các thành phần sẽ c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  \\\n",
       "0  <description><part\\\\_1> - Construct a rectangu...   \n",
       "1  <description>Part 1: Cylindrical Object with T...   \n",
       "2  <description>**Part 1: A rectangular prism wit...   \n",
       "3  <description>Part 1: Rectangular Table Top The...   \n",
       "4  <description> **Part 1: Building a rectangular...   \n",
       "\n",
       "                                           reasoning  \\\n",
       "0  <think>\\n***Step 1: Infer the components that ...   \n",
       "1  <think>\\n***Step 1: Infer the components that ...   \n",
       "2  <think>\\n***Step 1: Infer the components that ...   \n",
       "3  <think>\\n***Step 1: Infer the components that ...   \n",
       "4  <think>\\n***Step 1: Infer the components that ...   \n",
       "\n",
       "                                          completion  \\\n",
       "0  <json>\\n{\"parts\":{\"part_1\":{\"coordinate_system...   \n",
       "1  <json>\\n{\"parts\":{\"part_1\":{\"coordinate_system...   \n",
       "2  <json>\\n{\"parts\":{\"part_1\":{\"coordinate_system...   \n",
       "3  <json>\\n{\"parts\":{\"part_1\":{\"coordinate_system...   \n",
       "4  <json>\\n{\"parts\":{\"part_1\":{\"coordinate_system...   \n",
       "\n",
       "                                   description_trans  \\\n",
       "0  <description><part\\\\_1> - Dựng một lăng trụ đứ...   \n",
       "1  <description>Phần 1: Đối tượng hình trụ có đầu...   \n",
       "2  <description>**Phần 1: Lăng trụ chữ nhật có cạ...   \n",
       "3  <description>Phần 1: Mặt bàn hình chữ nhật Phầ...   \n",
       "4  <description> **Phần 1: Xây dựng một lăng trụ ...   \n",
       "\n",
       "                                     reasoning_trans  \n",
       "0  <think>\\n***Bước 1: Suy ra các thành phần sẽ c...  \n",
       "1  <think>\\n***Bước 1: Suy ra các thành phần sẽ c...  \n",
       "2  <think>\\n***Bước 1: Suy ra các thành phần sẽ c...  \n",
       "3  <think>\\n***Bước 1: Suy ra các thành phần sẽ c...  \n",
       "4  <think>\\n***Bước 1: Suy ra các thành phần sẽ c...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('h.csv')\n",
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "30fabccc-906d-40ee-a283-4f239d6ac7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' trình đùn',\n",
       " ' tính năng',\n",
       " '. </mô tả>',\n",
       " '.0</mô tả>',\n",
       " '0]</mô tả>',\n",
       " '44</mô tả>',\n",
       " '48</mô tả>',\n",
       " '5 </mô tả>',\n",
       " '7.</mô tả>',\n",
       " '75</mô tả>',\n",
       " ': Nối thân',\n",
       " '\\\\n</mô tả>',\n",
       " 'ao tác đùn',\n",
       " 'c tính nối',\n",
       " 'g khối mới',\n",
       " 'h năng cắt',\n",
       " 'hảo đã đùn',\n",
       " 'n vật liệu',\n",
       " 'pháp tuyến',\n",
       " 'ration\"\\n,\"',\n",
       " 'scription>',\n",
       " 't động nối',\n",
       " 'ớc khi đùn',\n",
       " 'ủa bộ phận'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = set()\n",
    "for row in df2['description_trans']:\n",
    "    \n",
    "    # x.add(row[row.find('<'):row.find('>')+1])\n",
    "    x.add(row[-12:])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e7d63ef6-4cf8-4718-b208-f6e5625da2aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "als = []\n",
    "for idx, row in df2.iterrows():\n",
    "    description = row['description_trans'].replace('<mô tả>', '<description>')\n",
    "    description = description.replace('</mô tả>', '</description>')\n",
    "    if description[-1] != '>':\n",
    "        description += '</description>'\n",
    "        \n",
    "    reasoning = row['reasoning_trans']\n",
    "    new_sample = {\n",
    "                    \"description\":description ,\n",
    "                    \"reasoning\":reasoning ,\n",
    "                    \"completion\": row['completion']\n",
    "                }\n",
    "    als.append(new_sample)\n",
    "# for row in df2['description_trans']:\n",
    "    \n",
    "    # x.add(row[row.find('<'):row.find('>')+1])\n",
    "    # x.add(row[-10:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "08e1748a-9ef7-4f44-a6de-38b7312fe8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "ds = Dataset.from_list(als)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9a594094-62ef-4a60-81d0-089b4dd24128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['description', 'reasoning', 'completion'],\n",
       "    num_rows: 10791\n",
       "})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0b7325-53a8-4d4e-8b79-218792dadaca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24aa5990672a49ec8a693f5549533848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db838197abe746119668c1e76ed91580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/11 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/TruongSinhAI/cad_reasoning/commit/e2a512d0be63fc629a83148bea531e59223d4e61', commit_message='Upload dataset', commit_description='', oid='e2a512d0be63fc629a83148bea531e59223d4e61', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/TruongSinhAI/cad_reasoning', endpoint='https://huggingface.co', repo_type='dataset', repo_id='TruongSinhAI/cad_reasoning'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "repo_id = \"TruongSinhAI/cad_reasoning\"\n",
    "token = \"tokennn\"  \n",
    "ds.push_to_hub(repo_id, private=False, token=token, split=\"data_vi\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Cad)",
   "language": "python",
   "name": "cad"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
